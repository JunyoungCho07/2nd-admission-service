import streamlit as st
import google.generativeai as genai
from pathlib import Path
import PyPDF2
import io

# --- ì´ˆê¸° ì„¤ì • ---

# st.session_state ì´ˆê¸°í™”
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'life_record' not in st.session_state:
    st.session_state.life_record = ""
if 'cover_letter' not in st.session_state:
    st.session_state.cover_letter = ""
if 'initial_result' not in st.session_state:
    st.session_state.initial_result = ""
if 'additional_questions' not in st.session_state:
    st.session_state.additional_questions = ""
if 'premium_report' not in st.session_state:
    st.session_state.premium_report = ""
if 'model_answers' not in st.session_state:
    st.session_state.model_answers = ""

# í”„ë¡¬í”„íŠ¸ ë¡œë“œ
try:
    prompt_path = Path(__file__).parent / "prompt_main.txt"
    AI_PROMPT = prompt_path.read_text(encoding="utf-8")
except FileNotFoundError:
    st.error("í•µì‹¬ í”„ë¡¬í”„íŠ¸ íŒŒì¼('prompt_main.txt')ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# API í‚¤ ì„¤ì •
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-1.5-pro-latest')
except (FileNotFoundError, KeyError):
    st.error("API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
def extract_text_from_pdf(pdf_file):
    if pdf_file is not None:
        try:
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() or ""
            return text
        except Exception as e:
            st.error(f"PDF íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return None
    return None

# --- ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ (UI) ---

st.markdown("<h1 style='text-align: center;'>ì••ë°• ë©´ì ‘ ì „ëµ ë¶„ì„ê°€</h1>", unsafe_allow_html=True)

# ì´ˆê¸° ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìœ¼ë©´ íŒŒì¼ ì—…ë¡œë“œ í™”ë©´ í‘œì‹œ
if not st.session_state.analysis_complete:
    st.markdown("<p style='text-align: center; font-size: 1.1em;'>ë‹¹ì‹ ì˜ ì„œë¥˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ë‚ ì¹´ë¡œìš´ ì˜ˆìƒ ì§ˆë¬¸ì„ ì¶”ì¶œí•˜ê³ , ì™„ë²½í•œ ë°©ì–´ ë…¼ë¦¬ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤.</p>", unsafe_allow_html=True)
    st.divider()
    st.subheader("1. ë¶„ì„ ìë£Œ ì—…ë¡œë“œ")
    st.write("ìƒê¸°ë¶€ì™€ ìì†Œì„œ PDF íŒŒì¼ì„ ê°ê° ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    col1, col2 = st.columns(2)
    with col1:
        life_record_file = st.file_uploader("ğŸ“„ ìƒí™œê¸°ë¡ë¶€ PDF ì—…ë¡œë“œ", type=['pdf'])
    with col2:
        cover_letter_file = st.file_uploader("âœï¸ ìê¸°ì†Œê°œì„œ PDF ì—…ë¡œë“œ", type=['pdf'])
    
    if st.button("ì´ˆê¸° ë¶„ì„ ë° ëŒ€í‘œ ì§ˆë¬¸ ì¶”ì¶œ", use_container_width=True, type="primary"):
        # ... (ì´ì „ ì½”ë“œì™€ ë™ì¼) ...
        if life_record_file and cover_letter_file:
            # ... (í…ìŠ¤íŠ¸ ì¶”ì¶œ ë¡œì§) ...
            life_record_text = extract_text_from_pdf(life_record_file)
            cover_letter_text = extract_text_from_pdf(cover_letter_file)

            if life_record_text and cover_letter_text:
                final_prompt = f"{AI_PROMPT}\n\n---\n[ì‚¬ìš©ì ì œì¶œ ìë£Œ]\n\n[ìƒê¸°ë¶€ ë‚´ìš©]:\n{life_record_text}\n\n[ìì†Œì„œ ë‚´ìš©]:\n{cover_letter_text}"
                
                with st.spinner("AIê°€ ì„œë¥˜ë¥¼ ì •ë°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    # ... (AI í˜¸ì¶œ ë° ìƒíƒœ ì €ì¥ ë¡œì§) ...
                    response = model.generate_content(final_prompt)
                    st.session_state.life_record = life_record_text
                    st.session_state.cover_letter = cover_letter_text
                    st.session_state.initial_result = response.text
                    st.session_state.analysis_complete = True
                    st.rerun()

# ì´ˆê¸° ë¶„ì„ì´ ì™„ë£Œë˜ë©´ ê²°ê³¼ ë° ì¶”ê°€ ê¸°ëŠ¥ ë²„íŠ¼ í‘œì‹œ
else:
    st.subheader("ğŸ“Š ì´ˆê¸° ë¶„ì„ ë³´ê³ ì„œ ë° ëŒ€í‘œ ì§ˆë¬¸")
    st.markdown(st.session_state.initial_result)
    st.divider()

    st.subheader("âš™ï¸ í”„ë¦¬ë¯¸ì—„ ê¸°ëŠ¥")
    st.write("ì„œë¥˜ì˜ ëª¨ë“  ì ì¬ì  ì•½ì ì„ íŒŒê³ ë“œëŠ” ì‹¬ì¸µ ë¶„ì„ì„ í†µí•´ ë©´ì ‘ì„ ì™„ë²½í•˜ê²Œ ëŒ€ë¹„í•˜ì„¸ìš”.")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ì¶”ê°€ ì§ˆë¬¸ ì¶”ì¶œ (20ê°œ)", use_container_width=True):
            with st.spinner("ì„œë¥˜ì˜ íŠ¹ì • ë¬¸ì¥ê³¼ ë‹¨ì–´ê¹Œì§€ íŒŒê³ ë“œëŠ” 20ê°œì˜ ì •ë°€ íƒ€ê²© ì§ˆë¬¸ì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
                additional_prompt = f"{AI_PROMPT}\n\n---\n[ì‚¬ìš©ì ì œì¶œ ìë£Œ]\n\n[ìƒê¸°ë¶€ ë‚´ìš©]:\n{st.session_state.life_record}\n\n[ìì†Œì„œ ë‚´ìš©]:\n{st.session_state.cover_letter}\n\n---\n[ì‚¬ìš©ì ëª…ë ¹ì–´]\nOn command: 'ì¶”ê°€ì§ˆë¬¸ì¶”ì¶œ'"
                response = model.generate_content(additional_prompt)
                st.session_state.additional_questions = response.text

    with col2:
        if st.button("í”„ë¦¬ë¯¸ì—„ ì¢…í•© ì „ëµ ë³´ê³ ì„œ", use_container_width=True):
            with st.spinner("í•©ê²© ì‹œë‚˜ë¦¬ì˜¤ì™€ 4D ì „ëµ ë¶„ì„ì„ í¬í•¨í•œ ìµœì¢… ë³´ê³ ì„œë¥¼ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
                report_prompt = f"{AI_PROMPT}\n\n---\n[ì‚¬ìš©ì ì œì¶œ ìë£Œ]\n\n[ìƒê¸°ë¶€ ë‚´ìš©]:\n{st.session_state.life_record}\n\n[ìì†Œì„œ ë‚´ìš©]:\n{st.session_state.cover_letter}\n\n---\n[ì‚¬ìš©ì ëª…ë ¹ì–´]\nOn command: 'ìƒê¸°ë¶€ë¶„ì„'"
                response = model.generate_content(report_prompt)
                st.session_state.premium_report = response.text

    with col3:
        if st.button("ì „ëµì  ëª¨ë²” ë‹µì•ˆ ìƒì„±", use_container_width=True):
            if not st.session_state.initial_result and not st.session_state.additional_questions:
                st.warning("ëª¨ë²” ë‹µì•ˆì„ ìƒì„±í•˜ë ¤ë©´ ë¨¼ì € ì§ˆë¬¸ì´ ì¶”ì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                with st.spinner("ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•œ ì „ëµì  ëª¨ë²” ë‹µì•ˆ íŒ¨í‚¤ì§€ë¥¼ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
                    # ìƒì„±ëœ ëª¨ë“  ì§ˆë¬¸ì„ ì·¨í•©
                    all_questions = st.session_state.initial_result + "\n\n" + st.session_state.additional_questions
                    answer_prompt = f"{AI_PROMPT}\n\n---\n[ì‚¬ìš©ì ì œì¶œ ìë£Œ]\n\n[ìƒê¸°ë¶€ ë‚´ìš©]:\n{st.session_state.life_record}\n\n[ìì†Œì„œ ë‚´ìš©]:\n{st.session_state.cover_letter}\n\n---\n[ë¶„ì„ëœ ì§ˆë¬¸ ëª©ë¡]\n{all_questions}\n\n---\n[ì‚¬ìš©ì ëª…ë ¹ì–´]\nOn command: 'ëª¨ë²”ë‹µì•ˆìƒì„±'"
                    response = model.generate_content(answer_prompt)
                    st.session_state.model_answers = response.text

    # ê° ê¸°ëŠ¥ì˜ ê²°ê³¼ê°€ ì¡´ì¬í•˜ë©´ ìˆœì„œëŒ€ë¡œ í™”ë©´ì— í‘œì‹œ
    if st.session_state.premium_report:
        st.divider()
        st.subheader("ğŸ“‘ í”„ë¦¬ë¯¸ì—„ ì¢…í•© ì „ëµ ë³´ê³ ì„œ")
        st.markdown(st.session_state.premium_report)

    if st.session_state.additional_questions:
        st.divider()
        st.subheader("ğŸ”¬ ì‹¬ì¸µ í•´ë¶€ ì§ˆë¬¸ (20ê°œ)")
        st.markdown(st.session_state.additional_questions)

    if st.session_state.model_answers:
        st.divider()
        st.subheader("ğŸ’¡ ì „ëµì  ëª¨ë²” ë‹µì•ˆ íŒ¨í‚¤ì§€")
        st.markdown(st.session_state.model_answers)